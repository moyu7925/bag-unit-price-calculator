#!/usr/bin/env python3
"""
GitHub Actions è‡ªåŠ¨ç›‘æ§å’Œä¿®å¤å·¥å…·
Automated monitoring and fixing tool for GitHub Actions
"""

import os
import sys
import time
import json
import subprocess
import requests
from datetime import datetime
from typing import Optional, Dict, List, Tuple
import re

class BuildMonitor:
    def __init__(self, config_file: str = "build_monitor_config.json"):
        self.config = self.load_config(config_file)
        self.repo_owner = self.config.get("repo_owner", "moyu7925")
        self.repo_name = self.config.get("repo_name", "bag-unit-price-calculator")
        self.branch = self.config.get("branch", "main")
        self.workflow_file = self.config.get("workflow_file", ".github/workflows/android.yml")
        self.github_token = os.environ.get("GITHUB_TOKEN", "")
        self.max_iterations = self.config.get("max_iterations", 30)
        self.check_interval = self.config.get("check_interval", 30)
        self.last_run_id = None
        self.fix_history = []

    def load_config(self, config_file: str) -> Dict:
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {e}")
        return {}

    def run_command(self, cmd: str, cwd: Optional[str] = None) -> Tuple[int, str, str]:
        try:
            result = subprocess.run(
                cmd, shell=True, cwd=cwd,
                capture_output=True, text=True, timeout=120
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Command timeout"
        except Exception as e:
            return -1, "", str(e)

    def git_commit_and_push(self, message: str) -> bool:
        print(f"ğŸ“ æäº¤æ›´æ”¹: {message}")
        
        self.run_command("git add .")
        self.run_command(f'git commit -m "{message}"')
        code, out, err = self.run_command("git push origin main")
        
        if code == 0:
            print("âœ… æ¨é€æˆåŠŸ")
            return True
        else:
            print(f"âŒ æ¨é€å¤±è´¥: {err}")
            return False

    def get_latest_workflow_run(self) -> Optional[Dict]:
        url = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}/actions/runs?per_page=3&branch={self.branch}"
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.github_token:
            headers["Authorization"] = f"token {self.github_token}"
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data.get("workflow_runs"):
                    return data["workflow_runs"][0]
        except Exception as e:
            print(f"âŒ è·å–å·¥ä½œæµçŠ¶æ€å¤±è´¥: {e}")
        return None

    def get_workflow_run_logs(self, run_id: int) -> Optional[str]:
        url = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/logs"
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.github_token:
            headers["Authorization"] = f"token {self.github_token}"
        
        try:
            response = requests.get(url, headers=headers, timeout=60)
            if response.status_code == 200:
                return response.text
        except Exception as e:
            print(f"âŒ è·å–æ—¥å¿—å¤±è´¥: {e}")
        return None

    def get_workflow_jobs(self, run_id: int) -> Optional[List[Dict]]:
        url = f"https://api.github.com/repos/{self.repo_owner}/{self.repo_name}/actions/runs/{run_id}/jobs"
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.github_token:
            headers["Authorization"] = f"token {self.github_token}"
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            if response.status_code == 200:
                data = response.json()
                return data.get("jobs", [])
        except Exception as e:
            print(f"âŒ è·å–Jobså¤±è´¥: {e}")
        return None

    def analyze_error(self, logs: str, jobs: Optional[List[Dict]] = None) -> Optional[str]:
        if not logs:
            return None
        
        log_lower = logs.lower()
        
        error_patterns = [
            ("aidl not found|aidl.*does not exist|cannot find aidl", "fix_aidl"),
            ("sdkmanager.*not found|sdkmanager.*does not exist", "fix_sdkmanager"),
            ("license.*not accepted|license.*rejected", "fix_license"),
            ("build-tools.*not found|cannot find build-tools", "fix_build_tools"),
            ("platform-tools.*not found|cannot find platform-tools", "fix_platform_tools"),
            ("ndk.*not found|cannot find ndk", "fix_ndk"),
            ("timeout|timed out", "fix_timeout"),
            ("memory.*exceeded|out of memory", "fix_memory"),
            ("disk.*space|no space left", "fix_disk"),
        ]
        
        for pattern, fix_type in error_patterns:
            if re.search(pattern, log_lower):
                return fix_type
        
        if jobs:
            for job in jobs:
                if job.get("conclusion") == "failure":
                    steps = job.get("steps", [])
                    for step in steps:
                        if step.get("conclusion") == "failure":
                            step_name = step.get("name", "").lower()
                            if "build" in step_name or "buildozer" in step_name:
                                return "fix_buildozer"
        
        return None

    def apply_fix(self, fix_type: str) -> bool:
        print(f"ğŸ”§ åº”ç”¨ä¿®å¤: {fix_type}")
        
        with open(self.workflow_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        applied_fixes = []
        
        if fix_type == "fix_aidl":
            if "platform-tools-latest-linux.zip" not in content:
                fix_code = '''         
         if [ ! -f "$ANDROID_HOME/platform-tools/aidl" ]; then
           echo "aidl not found, downloading platform-tools..."
           cd /tmp
           rm -rf platform-tools platform-tools.zip
           wget -q --tries=3 --timeout=30 https://dl.google.com/android/repository/platform-tools-latest-linux.zip -O platform-tools.zip
           unzip -q -o platform-tools.zip
           mkdir -p $ANDROID_HOME/platform-tools
           cp -rf platform-tools/* $ANDROID_HOME/platform-tools/
           chmod +x $ANDROID_HOME/platform-tools/aidl
         fi
         
         if [ -f "$ANDROID_HOME/platform-tools/aidl" ]; then
           echo "âœ“ aidl found"
           $ANDROID_HOME/platform-tools/aidl --version || true
         fi
'''
                if "Install Android SDK components" in content:
                    content = content.replace(
                        'sdkmanager --install "build-tools;34.0.0" || true',
                        'sdkmanager --install "build-tools;34.0.0" || true' + fix_code
                    )
                    applied_fixes.append("aidl_fix")
        
        elif fix_type == "fix_sdkmanager":
            if "commandlinetools-linux-11076708_latest.zip" not in content:
                fix_code = '''         
         mkdir -p $ANDROID_HOME/cmdline-tools
         cd /tmp
         if [ ! -f "cmdline-tools.zip" ]; then
           wget -q --tries=3 --timeout=30 https://dl.google.com/android/repository/commandlinetools-linux-11076708_latest.zip -O cmdline-tools.zip
         fi
         unzip -q -o cmdline-tools.zip
         rm -rf $ANDROID_HOME/cmdline-tools/latest
         mv cmdline-tools $ANDROID_HOME/cmdline-tools/latest
         chmod +x $ANDROID_HOME/cmdline-tools/latest/bin/*
'''
                if "Setup Android SDK" in content:
                    content = content.replace(
                        'mkdir -p $ANDROID_HOME/cmdline-tools',
                        fix_code
                    )
                    applied_fixes.append("sdkmanager_fix")
        
        elif fix_type == "fix_license":
            if "d56f5187479451eabf01fb78af6dfcb131a6481e" not in content:
                license_fix = '''        echo "d56f5187479451eabf01fb78af6dfcb131a6481e" > ~/.android/google-android-ndk-license
'''
                if "android-sdk-preview-license" in content:
                    content = content.replace(
                        'echo "84831b9409646a918e30573bab4c9c91346d8abd" > ~/.android/android-sdk-preview-license',
                        'echo "84831b9409646a918e30573bab4c9c91346d8abd" > ~/.android/android-sdk-preview-license\n' + license_fix
                    )
                    applied_fixes.append("license_fix")
        
        elif fix_type == "fix_build_tools":
            if "build-tools;34.0.0" not in content:
                content = content.replace(
                    'sdkmanager --install "build-tools;33.0.2" || true',
                    'sdkmanager --install "build-tools;33.0.2" || true\n        sdkmanager --install "build-tools;34.0.0" || true'
                )
                applied_fixes.append("build_tools_fix")
        
        elif fix_type == "fix_platform_tools":
            if "platform-tools" not in content:
                content = content.replace(
                    'yes | sdkmanager --licenses || true',
                    'yes | sdkmanager --licenses || true\n        sdkmanager --install "platform-tools" || true'
                )
                applied_fixes.append("platform_tools_fix")
        
        elif fix_type == "fix_timeout":
            if "timeout-minutes: 60" in content:
                content = content.replace(
                    "timeout-minutes: 60",
                    "timeout-minutes: 90"
                )
                applied_fixes.append("timeout_fix")
        
        elif fix_type == "fix_buildozer":
            if "MAX_RETRIES: 2" in content:
                content = content.replace(
                    "MAX_RETRIES: 2",
                    "MAX_RETRIES: 3"
                )
                applied_fixes.append("retry_fix")
        
        if applied_fixes and content != original_content:
            with open(self.workflow_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… åº”ç”¨äº†ä¿®å¤: {', '.join(applied_fixes)}")
            self.fix_history.append({
                "type": fix_type,
                "fixes": applied_fixes,
                "time": datetime.now().isoformat()
            })
            return True
        
        print("âš ï¸ æ— éœ€ä¿®å¤æˆ–æ— æ³•åº”ç”¨")
        return False

    def wait_for_new_run(self, current_run_id: int, timeout: int = 180) -> Optional[Dict]:
        print(f"â³ ç­‰å¾…æ–°çš„æ„å»º...")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            time.sleep(15)
            new_run = self.get_latest_workflow_run()
            if new_run and new_run.get("id") != current_run_id:
                print(f"âœ… æ£€æµ‹åˆ°æ–°æ„å»º #{new_run.get('id')}")
                return new_run
            print(".", end="", flush=True)
        
        print("\nâš ï¸ ç­‰å¾…è¶…æ—¶")
        return None

    def display_run_info(self, run: Dict):
        run_id = run.get("id", 0)
        status = run.get("status", "unknown")
        conclusion = run.get("conclusion", "unknown")
        created_at = run.get("created_at", "")
        html_url = run.get("html_url", "")
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ„å»ºä¿¡æ¯")
        print(f"{'='*60}")
        print(f"ID: {run_id}")
        print(f"çŠ¶æ€: {status}")
        print(f"ç»“æœ: {conclusion}")
        print(f"æ—¶é—´: {created_at}")
        print(f"é“¾æ¥: {html_url}")

    def monitor(self) -> bool:
        print("=" * 60)
        print("ğŸš€ GitHub Actions è‡ªåŠ¨ç›‘æ§å’Œä¿®å¤å·¥å…·")
        print("=" * 60)
        print(f"ğŸ“¦ ä»“åº“: {self.repo_owner}/{self.repo_name}")
        print(f"ğŸŒ¿ åˆ†æ”¯: {self.branch}")
        print(f"ğŸ“„ å·¥ä½œæµ: {self.workflow_file}")
        print(f"ğŸ”„ æœ€å¤§è¿­ä»£: {self.max_iterations}")
        print(f"â±ï¸ æ£€æŸ¥é—´éš”: {self.check_interval}ç§’")
        print("=" * 60)
        print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("=" * 60)
        
        for iteration in range(1, self.max_iterations + 1):
            print(f"\n{'='*60}")
            print(f"ğŸ”„ æ£€æŸ¥ #{iteration}/{self.max_iterations} | {datetime.now().strftime('%H:%M:%S')}")
            print(f"{'='*60}")
            
            run = self.get_latest_workflow_run()
            
            if not run:
                print("âš ï¸ æ— æ³•è·å–çŠ¶æ€ï¼Œç­‰å¾…åé‡è¯•...")
                time.sleep(self.check_interval)
                continue
            
            self.display_run_info(run)
            
            run_id = run.get("id", 0)
            status = run.get("status", "unknown")
            conclusion = run.get("conclusion", "unknown")
            
            if conclusion == "success":
                print("\n" + "ğŸ‰" * 20)
                print("ğŸ‰ æ„å»ºæˆåŠŸï¼")
                print("ğŸ‰" * 20)
                print(f"\nğŸ“¦ APKä¸‹è½½åœ°å€:")
                print(f"   {run.get('html_url', '')}#artifacts")
                print(f"\nâœ… ä¿®å¤å†å²:")
                for fix in self.fix_history:
                    print(f"   - {fix['type']}: {', '.join(fix['fixes'])} ({fix['time']})")
                print("\nâœ… ç›‘æ§å®Œæˆï¼")
                return True
            
            if status == "in_progress" or status == "queued":
                print("ğŸ”¨ æ„å»ºè¿›è¡Œä¸­...")
                self.last_run_id = run_id
                time.sleep(self.check_interval)
                continue
            
            if conclusion == "failure" or status == "completed":
                if run_id == self.last_run_id:
                    print("â­ï¸ åŒä¸€ä¸ªæ„å»ºï¼Œè·³è¿‡")
                    time.sleep(self.check_interval)
                    continue
                
                print("âŒ æ„å»ºå¤±è´¥ï¼Œåˆ†æé”™è¯¯...")
                
                jobs = self.get_workflow_jobs(run_id)
                logs = self.get_workflow_run_logs(run_id)
                fix_type = self.analyze_error(logs, jobs)
                
                if jobs:
                    print(f"\nğŸ“‹ Jobsä¿¡æ¯:")
                    for job in jobs:
                        job_name = job.get("name", "")
                        job_status = job.get("status", "")
                        job_conclusion = job.get("conclusion", "")
                        print(f"   {job_name}: {job_status} ({job_conclusion})")
                        
                        if job_conclusion == "failure":
                            steps = job.get("steps", [])
                            for step in steps:
                                if step.get("conclusion") == "failure":
                                    print(f"     âŒ å¤±è´¥æ­¥éª¤: {step.get('name')}")
                
                if logs:
                    log_lines = logs.split('\n')
                    print(f"\nğŸ“„ æ—¥å¿—é•¿åº¦: {len(log_lines)} è¡Œ")
                    
                    error_lines = []
                    for i, line in enumerate(log_lines[-100:]):
                        if any(kw in line.lower() for kw in ['error', 'failed', 'cannot', 'unable', 'exception']):
                            if line.strip() and len(line.strip()) > 10:
                                error_lines.append(line.strip())
                    
                    if error_lines:
                        print(f"\nğŸ” å…³é”®é”™è¯¯ä¿¡æ¯:")
                        for line in error_lines[-5:]:
                            print(f"   {line[:100]}")
                
                if fix_type:
                    print(f"\nğŸ”§ å‘ç°é—®é¢˜ç±»å‹: {fix_type}")
                    
                    if self.apply_fix(fix_type):
                        msg = f"Auto-fix: {fix_type} at {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                        print(f"\nğŸ“¤ æ¨é€ä¿®å¤...")
                        
                        if self.git_commit_and_push(msg):
                            print("â³ ç­‰å¾…æ–°æ„å»ºå¯åŠ¨...")
                            time.sleep(60)
                            self.last_run_id = run_id
                            continue
                        else:
                            print("âŒ æ¨é€å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                            return False
                    else:
                        print("âš ï¸ æ— æ³•åº”ç”¨ä¿®å¤")
                else:
                    print("âš ï¸ æ— æ³•è¯†åˆ«çš„é”™è¯¯ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†")
                    print("ğŸ’¡ æç¤º: æŸ¥çœ‹å®Œæ•´æ—¥å¿—ä»¥è·å–æ›´å¤šä¿¡æ¯")
                    print(f"   {run.get('html_url', '')}")
                    return False
            
            print(f"\nâ³ {self.check_interval}ç§’åé‡æ–°æ£€æŸ¥...")
            time.sleep(self.check_interval)
        
        print(f"\nâŒ å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({self.max_iterations})ï¼Œæ„å»ºä»æœªæˆåŠŸ")
        return False

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="GitHub Actions è‡ªåŠ¨ç›‘æ§å’Œä¿®å¤å·¥å…·")
    parser.add_argument("--config", default="build_monitor_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max-iterations", type=int, help="æœ€å¤§è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--check-interval", type=int, help="æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰")
    
    args = parser.parse_args()
    
    monitor = BuildMonitor(args.config)
    
    if args.max_iterations:
        monitor.max_iterations = args.max_iterations
    if args.check_interval:
        monitor.check_interval = args.check_interval
    
    try:
        success = monitor.monitor()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
        print("ç›‘æ§å·²åœæ­¢")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ç›‘æ§å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
